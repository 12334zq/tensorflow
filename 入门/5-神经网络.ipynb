{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:458: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:459: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:460: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:461: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:462: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:465: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/4.png\" alt=\"FAO\" width=\"790\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单层神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/5.png\" alt=\"FAO\" width=\"790\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numClasses = 10 \n",
    "inputSize = 784 \n",
    "numHiddenUnits = 50 \n",
    "trainingIterations = 10000 \n",
    "batchSize = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None, inputSize])\n",
    "y = tf.placeholder(tf.float32, shape = [None, numClasses])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参数初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.truncated_normal([inputSize, numHiddenUnits], stddev=0.1))\n",
    "B1 = tf.Variable(tf.constant(0.1), [numHiddenUnits])\n",
    "W2 = tf.Variable(tf.truncated_normal([numHiddenUnits, numClasses], stddev=0.1))\n",
    "B2 = tf.Variable(tf.constant(0.1), [numClasses])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddenLayerOutput = tf.matmul(X, W1) + B1\n",
    "hiddenLayerOutput = tf.nn.relu(hiddenLayerOutput)\n",
    "finalOutput = tf.matmul(hiddenLayerOutput, W2) + B2\n",
    "finalOutput = tf.nn.relu(finalOutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "网络迭代"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y, logits = finalOutput))\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate = .1).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(finalOutput,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.1\n",
      "step 1000, training accuracy 0.95\n",
      "step 2000, training accuracy 0.94\n",
      "step 3000, training accuracy 0.96\n",
      "step 4000, training accuracy 1\n",
      "step 5000, training accuracy 0.99\n",
      "step 6000, training accuracy 0.98\n",
      "step 7000, training accuracy 1\n",
      "step 8000, training accuracy 0.98\n",
      "step 9000, training accuracy 0.99\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(trainingIterations):\n",
    "    batch = mnist.train.next_batch(batchSize)\n",
    "    batchInput = batch[0]\n",
    "    batchLabels = batch[1]\n",
    "    _, trainingLoss = sess.run([opt, loss], feed_dict={X: batchInput, y: batchLabels})\n",
    "    if i%1000 == 0:\n",
    "        trainAccuracy = accuracy.eval(session=sess, feed_dict={X: batchInput, y: batchLabels})\n",
    "        print (\"step %d, training accuracy %g\"%(i, trainAccuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "两层神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.15\n",
      "step 1000, training accuracy 0.93\n",
      "step 2000, training accuracy 0.99\n",
      "step 3000, training accuracy 0.98\n",
      "step 4000, training accuracy 0.97\n",
      "step 5000, training accuracy 0.98\n",
      "step 6000, training accuracy 1\n",
      "step 7000, training accuracy 1\n",
      "step 8000, training accuracy 1\n",
      "step 9000, training accuracy 1\n",
      "testing accuracy: 0.9728999733924866\n"
     ]
    }
   ],
   "source": [
    "\n",
    "numHiddenUnitsLayer2 = 100\n",
    "trainingIterations = 10000\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, inputSize])\n",
    "y = tf.placeholder(tf.float32, shape = [None, numClasses])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([inputSize, numHiddenUnits], stddev=0.1))\n",
    "B1 = tf.Variable(tf.constant(0.1), [numHiddenUnits])\n",
    "W2 = tf.Variable(tf.random_normal([numHiddenUnits, numHiddenUnitsLayer2], stddev=0.1))\n",
    "B2 = tf.Variable(tf.constant(0.1), [numHiddenUnitsLayer2])\n",
    "W3 = tf.Variable(tf.random_normal([numHiddenUnitsLayer2, numClasses], stddev=0.1))\n",
    "B3 = tf.Variable(tf.constant(0.1), [numClasses])\n",
    "\n",
    "hiddenLayerOutput = tf.matmul(X, W1) + B1\n",
    "hiddenLayerOutput = tf.nn.relu(hiddenLayerOutput)\n",
    "hiddenLayer2Output = tf.matmul(hiddenLayerOutput, W2) + B2\n",
    "hiddenLayer2Output = tf.nn.relu(hiddenLayer2Output)\n",
    "finalOutput = tf.matmul(hiddenLayer2Output, W3) + B3\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y, logits = finalOutput))\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate = .1).minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(finalOutput,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(trainingIterations):\n",
    "    batch = mnist.train.next_batch(batchSize)\n",
    "    batchInput = batch[0]\n",
    "    batchLabels = batch[1]\n",
    "    _, trainingLoss = sess.run([opt, loss], feed_dict={X: batchInput, y: batchLabels})\n",
    "    if i%1000 == 0:\n",
    "        train_accuracy = accuracy.eval(session=sess, feed_dict={X: batchInput, y: batchLabels})\n",
    "        print (\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "\n",
    "testInputs = mnist.test.images\n",
    "testLabels = mnist.test.labels\n",
    "acc = accuracy.eval(session=sess, feed_dict = {X: testInputs, y: testLabels})\n",
    "print(\"testing accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
